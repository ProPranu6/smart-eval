# -*- coding: utf-8 -*-
"""SmartEval

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BuBdiioR7jSg0upTGXpF3vwcFsfXE6g-
"""

!pip install sentence-transformers

!pip install textblob
!pip install symspellpy
!pip install tqdm

from sentence_transformers import SentenceTransformer
import sklearn
import numpy as np
import warnings
import re
from textblob import TextBlob
from symspellpy.symspellpy import SymSpell
from tqdm import tqdm
import pandas as pd


warnings.filterwarnings("ignore")


def abbreviate_in_sen(sen, show_abbreviated=True):
  #sen = 'KL is a powerful way to automate things today'
  acronyms = re.findall('[A-Z][A-Z]+',sen)
  for acronym in acronyms:
    try:
      sen = re.sub(acronym, abbr_vocab[acronym],sen)
    except:
      new_acronym = acronym
      abbr_vocab[new_acronym] = new_acronym #"<undefined abbreviation>"
      print('New Abbreviation Vocab', new_acronym, 'detected')
      sen = re.sub(acronym, abbr_vocab[acronym],sen)
  
  if show_abbreviated:
        print(sen)
  return sen
    

def evaluate(student_answer=None, teacher_answer=None, abbr_vocab=None, gen_context_spread=50, spell_check='None', student_id=-1, question_id=-1):

  #Acronym Replacement helps pick right match( because the trained data are highly likely to have seen abbreviations than acronyms and thus they know the context well when they have seen it)
  #Removing the stop words significantly improves the preference ratio but could affect negation statements try and use later
  #Passive and Active vocies are calculated well
  
  if student_answer == None or teacher_answer == None or abbr_vocab == None:

    print("Running Evaluation On Default Inputs")
    abbr_vocab = {'AI':'artificial intelligence', 'ML':'machine learning', 'DL' : 'deep learning', 'DS' : 'data science'}
    student_answer = 'The prominence of AI today has grown lot Artificial intelligence receives, understands and manipulates the world artificial intelligence is used to automate things'
    teacher_answer = 'AI is an important field present day Artificial intelligence means to be able to receive, understand, reason and change the environment AI is used to automate things'

    print("Student Answer : ")
    print(student_answer)

    print("Teacher Answer : ")
    print(teacher_answer)

  student_answer = re.sub("\\n+|\t+", " " , student_answer)
  teacher_answer = re.sub("\\n+|\t+", " ", teacher_answer)
  
  student_answer = re.sub("[0-9]+", "" , student_answer)
  teacher_answer = re.sub("[0-9]+", "", teacher_answer)

  teacher_answer_chunks = []
  student_answer_chunks = []

  con_student_sen = ""
  con_teacher_sen = ""
  count_stu = 1
  count_tea = 1

  path = '/content/all_raw_answers.txt'
  try:
    fil = open(path, 'x')
    fil.close()
  except:
    pass

  fil = open(path,'w')
  fil.write(teacher_answer+" "+student_answer)
  fil.close()

  corrector = SymSpell(count_threshold=3)
  corrector.create_dictionary('/content/all_raw_answers.txt')
  for wds in teacher_answer.split(" "):
    if spell_check == 'symspell':
      wds = corrector.lookup(wds, verbosity=3, include_unknown=True, ignore_token='[A-Z][A-Z]+')[0].term
    con_teacher_sen += wds + " "
    if count_tea%(min(127, gen_context_spread)+1) == 0:
      teacher_answer_chunks.append(con_teacher_sen)
      con_teacher_sen = ""
    count_tea += 1
  teacher_answer_chunks.append(con_teacher_sen)

  for wds in student_answer.split(" "):
    if spell_check == 'symspell':
      wds = corrector.lookup(wds, verbosity=3, include_unknown=True, ignore_token='[A-Z][A-Z]+')[0].term
    con_student_sen += wds + " "
    if count_stu%(min(720, gen_context_spread)+1) == 0:
      student_answer_chunks.append(con_student_sen)
      con_student_sen = ""
    count_stu += 1
  student_answer_chunks.append(con_student_sen)

  

  teacher_answer_chunks = [TextBlob(abbreviate_in_sen(se, show_abbreviated=False)).correct().string if spell_check == 'textblob' else abbreviate_in_sen(se, show_abbreviated=False) for se in teacher_answer_chunks]
  student_answer_chunks = [TextBlob(abbreviate_in_sen(se, show_abbreviated=False)).correct().string if spell_check == 'textblob' else abbreviate_in_sen(se, show_abbreviated=False) for se in student_answer_chunks]

  models = ['paraphrase-mpnet-base-v2', 'sentence-transformers/all-MiniLM-L12-v1', 'multi-qa-MiniLM-L6-cos-v1']
  correctnesses = []
  for model in tqdm(range(len(models)), desc='Evaluating Student' +str(student_id)+' against Question' + str(question_id)+' ...', ncols=100):
    encoder = SentenceTransformer(models[model])
    embed_teacher_answer = encoder.encode(teacher_answer_chunks)
    embed_student_answer = encoder.encode(student_answer_chunks)

    #embeds_student_answer = embed_student_answer
    #embeds_teacher_answer = embed_teacher_answer

    embed_student_answer = np.expand_dims(np.mean(embed_student_answer, axis=0), axis=0)
    embed_teacher_answer = np.expand_dims(np.mean(embed_teacher_answer, axis=0), axis=0)



    #print(embed_student_answer.shape)
    #print(embed_teacher_answer.shape)

    correctness = sklearn.metrics.pairwise.cosine_similarity(embed_teacher_answer, embed_student_answer, dense_output=True)[0][0] #rows are teacher_sens, cols are student_sens
    #print("Correctnesses : ", correctness)
    correctnesses.append(correctness)
  print("\nDone")
  correctnesses.append(np.mean(np.array(correctnesses), axis=0))
  return correctnesses, teacher_answer_chunks, student_answer_chunks

def report_card(answers_path, class_strength=52, max_marks=5):
  answers = pd.read_csv(answers_path)
  student_marks = dict()
  for stu in range(class_strength):
    student_marks["Student " + str(stu+1)] = []
  
 
  teacher_answer = answers['teacher answer'][0]
  question_count = 0
  for row in range(class_strength): #it's row count = class_strength*questions = len
      if row%class_strength == 0:
        teacher_answer = answers['teacher answer'][row]
        question_count += 1
      correctnesses, _, _ = evaluate(answers['student answer'][row], teacher_answer, abbr_vocab={}, gen_context_spread=75, spell_check='symspell', student_id = row%class_strength+1, question_id=question_count)
      student_marks["Student " + str(row%class_strength+1)].append(correctnesses[-1])
  
  report = student_marks
  report_norm = np.empty((question_count, class_strength)) #it's row = class_strength*questions = len
  for r in range(question_count):
    for c in range(class_strength):
      report_norm[r][c] = report["Student " + str(c+1)][r]

  report_norm_copy = copy.deepcopy(report_norm) #max mark
  
  for r in range(question_count):
    true_max = max(report_norm_copy[r])
    true_min = 0 
    for c in range(class_strength):
      report_norm[r][c] = np.round((report_norm_copy[r][c]-true_min)/(true_max-true_min)*max_marks, decimals=1) # mark = normalize(percentage), base_min_mark = 0, base_max_mark = true_max
  
  for stu in range(class_strength):
    student_marks["Student " + str(stu+1)] = report_norm[:, stu]
  return student_marks

if __name__ == "__main__":
  report_card('/content/exam-dataset-1.csv', class_strength=11, max_marks=10)
  tea = "Viruses, worms, trojans, and downloads"
  stu = "Viruses are malicious programs that associate with other programs and when they run, they multiply, worms directly target security holes in the system, Trojans are peaceful in appearance, but their interior is malicious, download programs make viruses and when working on the computer they activate and spread viruses."
  evaluate(stu, tea, abbr_vocab={}, gen_context_spread=75, spell_check="None")



